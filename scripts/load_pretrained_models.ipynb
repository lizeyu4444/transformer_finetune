{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from transformers import EvalPrediction\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "from transformers import Trainer, TrainingArguments, set_seed\n",
    "from transformers import GlueDataTrainingArguments, GlueDataset, glue_output_modes, glue_tasks_num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 导入旧模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './multilingual_sentiment_vocab20k'\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1609, 0.1715, 0.1642, 0.2521, 0.2513]])\n",
      "4 stars\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('a synthesis of cliches and absurdities that seems positively decadent in its cinematic flash and emptiness ')\n",
    "input_ids = torch.tensor([input_ids])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "predictions = softmax(predictions)\n",
    "print(predictions)\n",
    "index_pred = torch.argmax(predictions[0, :]).item()\n",
    "label_pred = config.id2label[index_pred]\n",
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 导入训练好的SST-2模型(from Glue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 it offers little beyond the momentary joys of pretty and weightless intellectual entertainment . \n",
      "0 a synthesis of cliches and absurdities that seems positively decadent in its cinematic flash and emptiness . \n",
      "1 a subtle and well-crafted ( for the most part ) chiller . \n",
      "1 has a lot of the virtues of eastwood at his best . \n",
      "0 it 's hampered by a lifetime-channel kind of plot and a lead actress who is out of her depth . \n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/home/edili/download/downloads/glue/SST-2/'\n",
    "dev = pd.read_csv(DATA_DIR+'dev.tsv', delimiter='\\t')\n",
    "for i in dev.head(50).tail().values:\n",
    "    print(i[1],i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/tmp/SST-2'\n",
    "\n",
    "config = AutoConfig.from_pretrained(ckpt_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt_path)\n",
    "model_ft = AutoModelForSequenceClassification.from_pretrained(ckpt_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9823, 0.0177]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('a synthesis of cliches and absurdities that seems positively decadent in its cinematic flash and emptiness ')\n",
    "input_ids = torch.tensor([input_ids])\n",
    "\n",
    "model_ft.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model_ft(input_ids)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "predictions = softmax(predictions)\n",
    "print(predictions)\n",
    "index_pred = torch.argmax(predictions[0, :]).item()\n",
    "index_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 导入训练好的新闻情感模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt_path = '/tmp/st_news'\n",
    "\n",
    "config = AutoConfig.from_pretrained(ckpt_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt_path)\n",
    "model_ft = AutoModelForSequenceClassification.from_pretrained(ckpt_path, config=config)\n",
    "_ = model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    input_ids = tokenizer.encode(sentence)\n",
    "    input_ids = torch.tensor([input_ids])\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ft(input_ids)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    predictions = softmax(predictions)\n",
    "    index_pred = torch.argmax(predictions[0, :]).item()\n",
    "    prob = predictions.numpy()[0, index_pred]\n",
    "    return index_pred, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.9044954)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '【建投中小盘】一周策略回顾与展望2020-04-13'\n",
    "predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
